{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hw 4: More Linear Regression ðŸŽ¢"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Riley Hager\n",
    "\n",
    "Student ID: 455336\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "For this homework, work through **Lab 0 (Intorduction to Python)** first. Most of the things we ask you to do in this homework are explained in the lab. Note that Lab 0 covers more content than we ask you to provide for this homework, so make sure you actually work through the entire notebook!\n",
    "\n",
    "### Submission instructions\n",
    "* Submit this python notebook including your answers in the code cells as homework submission.\n",
    "* **Do not change the number of cells!** Your submission notebook should have exactly one code cell per problem. \n",
    "* Do **not** remove the `# your code here` line and add you solution after that line. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Linear Regression with More Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this weeks lab, we implemented a linear regression model that could map a single predictor feature to a target variable. In the case of the Boston housing dataset, we could map features like the \"average number of rooms per dwelling\" to a houses price. In reality, however, a single predictor is not enough to get a good model. Additionally, we have data for several predictors so why not make use of that?\n",
    "\n",
    "In this series of problems, let's explore how we can build a multi-dimensional linear model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-Learn\n",
    "\n",
    "Generalizing our derivation of 1D linear regression to many-dimensionional is non-trivial since we would need to convert our computations into matrix operations, which are beyond the scope of this class. However, that does not mean that we can't play do many-dimensional linear regression. The package we will introduce today is [Scikit-learn](https://scikit-learn.org/stable/). It contains many generalized implementations of common learning models and we will be using its implementation of multi-dimensional linear regression for here.\n",
    "\n",
    "You have already seen Scikit-learn, or `sklearn`, before since that is where we got our Boston housing data in the lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = boston.data, boston.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `sklearn` is very similar to our implementation from the lab, though there is a slight difference: we work with a model object. In the following cell, we create an instance of linear regression model called `model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `fit` and `predict` functions that we used previously are analogous to the `fit` and `predict` methods of `model`. Here is a quick example of how to perform 1D linear regression mapping the `CRIM` predictor to housing price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 24.03048217,  23.99354274,  23.95660331, ..., -12.83506817,\n",
       "       -12.8720076 , -12.90894703])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'CRIM'\n",
    "x_crim = X[:, boston.feature_names.tolist().index(target)].reshape(-1, 1)\n",
    "\n",
    "# you should create a new model object for each new model you create\n",
    "model = LinearRegression()\n",
    "\n",
    "# fitting the model\n",
    "model.fit(x_crim, y)\n",
    "\n",
    "# predicting with the model\n",
    "import numpy as np\n",
    "\n",
    "x_star = np.linspace(x_crim.min(), x_crim.max(), 1001).reshape(-1, 1)\n",
    "model.predict(x_star)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1.1\n",
    "\n",
    "**Write-up!** There are several things wrong with the example above. What do you see? `HINT`: think back to the model building part of the data science workflow."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# your response here\n",
    "The model is done using lists instead of NumPy arrays, which makes it less efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1.2\n",
    "\n",
    "Now that we are familiar with `sklearn`, let's start building a linear model that uses all of the features in our dataset. You can see the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) for more information about how to use `LinearRegression`.\n",
    "\n",
    "**Try this!** Build a model that uses _all_ of the predictor features in the Boston housing dataset. Remember to create a new instance of `LinearRegression` and assign it to the `model` variable. Also make sure that you do a train/test split of your data so we can evaluate our model after training (use `random_state=10` so we can compare our results to the ones from `Lab4`; refer to the lab for an example of how to do this). If you were successful, you will see the weights for the model below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.53305138282441\n",
      "[-1.28180656e-01  6.31981786e-02 -7.57627602e-03  1.97451452e+00\n",
      " -1.62719890e+01  3.10845625e+00  1.62922153e-02 -1.48301360e+00\n",
      "  3.03988206e-01 -1.20820710e-02 -8.20305699e-01  1.14189890e-02\n",
      " -5.81626431e-01]\n",
      "(13,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# your code here\n",
    "model = LinearRegression()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Get the model parameters\n",
    "b = model.intercept_\n",
    "w = model.coef_\n",
    "\n",
    "print(b)\n",
    "print(w)\n",
    "\n",
    "# Now, w is a vector! With a weight parameter for every feautre.\n",
    "print(w.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1.3\n",
    "\n",
    "Now that we have a trained model, we can use it to make some predictions using the testing set.\n",
    "\n",
    "**Try this!** Use your model to compute the predicted prices of the points in your testing set and store these into the variable `y_prediction`. Then, compute the RMSE of these predictions and store the value in `rmse`. If all went well you should see the RMSE value you computed as the output of the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RMSE: 5.866341999333012'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "from sklearn.metrics import mean_squared_error\n",
    "y_prediction = model.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_prediction))\n",
    "\n",
    "assert np.isscalar(rmse), 'RMSE should be a scalar value'\n",
    "\n",
    "f'RMSE: {rmse}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1.4\n",
    "\n",
    "Let's talk about this result.\n",
    "\n",
    "**Write-up!** What did you notice about this result and how does it compare to those of individual predictors from `Lab4`? Is this what you expected to see?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# your response here\n",
    "The root mean square error is approximately half of that in Lab 4. This is consistent with what is expected because of the higher accuracy of this calculation (using more features)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Introducing a New Metric\n",
    "\n",
    "RMSE is a good measure for how well a model fits, but one could argue it is not the most intuitive. An alternative measure is $R^2$, or the **coefficient of determination**, which is essentially a measure of how close the data are to the fitted regression line. Whereas RMSE is a number in the units of the original target variable, $R^2$ is a value between 0 and 1, where increasing values indicate better fit. In this way, $R^2$ is a good place to start when evaluating a regression model because it is easy to interpret.\n",
    "\n",
    "$$R^2 = 1 - \\frac{\\displaystyle \\frac{1}{n} \\sum_{n=1}^n (y_i - f(x_i))^2}{\\displaystyle \\frac{1}{n} \\sum_{n=1}^n (y_i - \\bar y)^2}$$\n",
    "\n",
    "> _For those who are interested_: Those of you that are statistically savvy, or just simply read the lab, will remember that these sums are mean squared errors. The numerator is the MSE of the true values compared to the predicted value and the denominator is the MSE of the true value relative to the mean value. The denominator is the variance of the response variable (eg. house price). One way to interpret this metric is that it computes the the ratio between how much variation is explained by the model and the total variation in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.1\n",
    "\n",
    "**Try this!** Complete the function below so that it computes the $R^2$ value of a model given some `predictions` and their true `labels`. To receive full credit, implement the math yourself; do not rely on other, already implemented functions. Store your computed result in the `r2` variable.\n",
    "\n",
    "> Do **not** use any built-in functions from scikit-learn for this problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_squared(predictions, labels):\n",
    "    '''computes the r-squared metric of a model given some PREDICTIONS and their true LABELS'''\n",
    "    \n",
    "    # your code here\n",
    "    r2 = 1 - (mean_squared_error(y_test, y_prediction))/np.var(y_test)\n",
    "    assert np.isscalar(r2), 'R2 should be a scalar value'\n",
    "    \n",
    "    return r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your computation is correct, the following assertion will run without error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.isclose(r_squared(y_prediction, y_test), model.score(X_test, y_test)), 'The value computed was incorrect'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Using a More Complex Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of options we can choose from when it comes to picking a model to use when analyzing our data. In this section, we will take a look at a more complex model: **polynomial regression**. We will also investigate some of the considerations one should make when picking a model.\n",
    "\n",
    "![poly_reg](https://www.oreilly.com/library/view/hands-on-machine-learning/9781491962282/assets/mlst_04in03.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back to Toy Data\n",
    "\n",
    "As mentioned in earlier, it is really hard to visualize many-dimensional datasets so for this section we will fallback to the toy data we used from `Lab4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = np.loadtxt('utility/data/toy_data.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polynomial regression models are really just extensions of the linear models that we are already familiar with. The difference comes from how we preprocess our data. The specifics of how this works is beyond the scope of this course (see CSE417 for more information)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to build a polynomial model, we will need to do some preparation. `sklearn`'s models require that the input data is a $n$-dimensional array. Since our input array `x` is a 1D array for the toy data set, we will need to do is to reshape it into a 2D array. The function in the following cell, `reshape` will take care of this for you â€” use it when applicable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshape = lambda x: x.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3.1\n",
    "\n",
    "The next thing we will need to do is to fit a linear model that will serve as our baseline.\n",
    "\n",
    "**Try this!** Create a new linear model and fit it with the toy data set and create a plot showing the scattered data points `x, y` and the predicted values of fthe model.You don't need to worry about making a train/test split for this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1a1e179b38>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [16,9]\n",
    "plt.rcParams['axes.titlesize'] = 20\n",
    "plt.rcParams['axes.labelsize'] = 16\n",
    "plt.rcParams['xtick.labelsize'] = 14\n",
    "plt.rcParams['ytick.labelsize'] = 14\n",
    "plt.rcParams['lines.linewidth'] = 2\n",
    "\n",
    "# your code here\n",
    "linear_model = LinearRegression()\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doing Polynomial Regression\n",
    "\n",
    "Next, let's implement a function that produces fitted polynomial regression models. Again, you don't need to worry too much about how this works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "def make_poly(x, y, degree=2):\n",
    "    '''creates and returns a polynomial regression model fit with input data X and Y'''\n",
    "    \n",
    "    polynomial_features = PolynomialFeatures(degree=degree)\n",
    "    poly_model = Pipeline([(\"polynomial_features\", polynomial_features),\n",
    "                           (\"linear_regression\", LinearRegression())])\n",
    "\n",
    "    return poly_model.fit(reshape(x), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3.2\n",
    "\n",
    "Let's try using the `make_poly` function.\n",
    "\n",
    "**Try this!** Use `make_poly` to, well, make a polynomial regression model with a `degree` of 2. This model will fit the data with a quadratic function. Store the model you created in `poly2_model` and create a plot showing the scattered data points `x, y` and the predicted values of the model. Make sure your graph has the proper components. `HINT` you will need to make an array of equally spaced values over an interval (see [`np.linspace`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linspace.html)) for your predicted values; refer to `Lab4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (1000,) and (102,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-1845016cac50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mx_star\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_star\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_prediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"orange\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mpoly2_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_poly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2811\u001b[0m     return gca().plot(\n\u001b[1;32m   2812\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2813\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1810\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1611\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1612\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_grab_next_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[0;32m--> 231\u001b[0;31m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (1000,) and (102,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# your code here\n",
    "x_star = np.linspace(0, x.max(), 1000)\n",
    "plt.scatter(x, y)\n",
    "plt.plot(x_star, y_prediction, color=\"orange\")\n",
    "poly2_model = make_poly(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3.3\n",
    "\n",
    "Nice that worked well! Let's up the complexity again. Try to play around with the degree and find the one that produces the \"best-fitting\" model.\n",
    "\n",
    "**Try this!** Use `make_poly` and try to find the \"best-fitting\" model by expermenting with the `degree` argument. Store this model in `poly_best_model`. Then, create a plot showing the scattered data points `x, y` and the predicted values of the model. Make sure your graph has the proper components. `HINT` you can use the `r_squared` metric you implemented from before to evaluate the fit of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Models\n",
    "\n",
    "Let's compare the RMSE and $R^2$ metrics for the models that we have produced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3.4\n",
    "\n",
    "**Try this!** Fill in the following `for` loop to print out the RMSE and $R^2$ metrics for each model in `models`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LinearRegression' object has no attribute 'labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-495ab72f8f16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# your code here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#print(rsme(linear_model))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr_squared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'LinearRegression' object has no attribute 'labels'"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    'Linear': linear_model,\n",
    "    #'2nd Order Polynomial': poly2_model,\n",
    "    #'Best Fitting Polynomial': poly_best_model\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    # your code here\n",
    "    #print(rsme(linear_model))\n",
    "    print(r_squared(linear_model.predict, linear_model.labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3.5\n",
    "\n",
    "**Write-up!** What do you notice about the scores? Given these results, which model would you pick to deliver to a client? Why?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# your response here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking Up Against the Real Function\n",
    "\n",
    "What if I told you the true function was $$y = 0.15x + 20$$\n",
    "\n",
    "The following function, `ground_truth`, will return `x` and `y` values produced by the true function with some added noise. We can use this to produce other points that could have been generated by the same function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ground_truth(n):\n",
    "    '''returns N random samples from the function above'''\n",
    "    \n",
    "    w, b = 0.15, 20\n",
    "    noise = np.random.rand(n) * 300\n",
    "    x = np.random.randint(0, 2000, n)\n",
    "    y = w * x + b + noise\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3.6\n",
    "\n",
    "**Try this!** With `ground_truth`, make a plot that shows points these four things:\n",
    "1. The points from the toy dataset\n",
    "2. 200 points generated from the true function\n",
    "3. The linear model\n",
    "4. The \"best-fit\" polynomial model\n",
    "\n",
    "You don't need to retrain the models for this part. To receive full points, ensure that your plot has all of the proper components, including a legend (see `Lab4` for an example of how to do this)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3.7\n",
    "\n",
    "**Write-up!** What happened in the plot from [Problem 3.6](#Problem-3.6)? What does the tell us about model complexity? Why must we be careful of the models that we use to analyze our data?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# your response here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we're done."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
